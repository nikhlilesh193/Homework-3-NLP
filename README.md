üìò CS5760 ‚Äì Natural Language Processing

## Homework 3

**Student Name:** Nikhilesh Katakam
**University:** University of Central Missouri 
700#: 700772365

---

## üìå Overview

This repository contains solutions for **Homework 3** of CS5760 ‚Äì Natural Language Processing.

The assignment covers core NLP and Machine Learning concepts including:

* Sigmoid Classification
* Stochastic Gradient Descent (SGD)
* Cosine Similarity
* TF-IDF Ranking
* PMI vs PPMI
* Generative vs Discriminative Models
* Cross-Entropy Loss
* NLP Representation Concepts

---

## üßÆ Part I ‚Äì Writing Calculations

### 1Ô∏è‚É£ Sigmoid Classification

* Computed linear combination
* Applied sigmoid activation
* Predicted class using threshold

### 2Ô∏è‚É£ One SGD Update Step

* Forward pass
* Gradient computation
* Weight and bias update

### 3Ô∏è‚É£ Cosine Similarity

* Dot product calculation
* Vector magnitudes
* Final cosine similarity score

### 4Ô∏è‚É£ TF-IDF Ranking

* Term-level TF-IDF computation
* Document score calculation
* Ranking of documents

### 5Ô∏è‚É£ PMI vs PPMI

* PMI calculation
* Conversion to PPMI

---

## ‚úçÔ∏è Part II ‚Äì Short Answers

Topics covered:

* Generative vs Discriminative Models
* Cross-Entropy Loss
* Synonymy vs Word Similarity
* TF-IDF vs Raw Term Frequency
* PPMI and Negative PMI Interpretation

---

## üìö Concepts Used

* Logistic Regression
* Binary Cross-Entropy Loss
* Gradient Descent
* Vector Space Models
* Information Theory
* Document Representation

---
